def generate_full_music(user_story):
        """
        Full pipeline: analyze emotion, generate brief, and create actual music
        Uses cached results if available for the same story
        
        Args:
            user_story (str): User's emotional story/text
        
        Returns:
            tuple: (emotion_analysis, music_brief, audio_file, status_message)
        """
        try:
            if app_state.user_story != user_story:
                app_state.clear()
                app_state.user_story = user_story
            
            # Prepare the state
            state = {
                "user_text": user_story,
                "force_generate": True  # Force music generation
            }
            
            if app_state.has_emotion_analysis(user_story):
                state["emotion"] = app_state.emotion_result
                status_msg = "ğŸ“‹ ì´ì „ ê°ì • ë¶„ì„ ê²°ê³¼ ì¬ì‚¬ìš©"
            
            if app_state.has_music_brief(user_story):
                state["brief"] = app_state.music_brief
                status_msg = "ğŸ“‹ ì´ì „ ë¶„ì„ ê²°ê³¼ ì¬ì‚¬ìš©í•˜ì—¬ ìŒì•… ìƒì„±"
            
            # Run the workflow (will skip already completed steps)
            final_state = graph.invoke(state)
            
            # Extract results
            emotion = final_state.get("emotion")
            brief = final_state.get("brief")
            audio_path = final_state.get("audio_path")
            provider_used = final_state.get("provider_used", "skipped")
            
            emotion_text = f"""**ğŸ­ ì£¼ìš” ê°ì •**: {emotion.primary}

**ğŸ“Š ê°ì • ê°•ë„ (Valence)**: {emotion.valence:.2f}
*(-1: ë§¤ìš° ë¶€ì •ì  â†” +1: ë§¤ìš° ê¸ì •ì )*

**âš¡ ê°ì„±ë„ (Arousal)**: {emotion.arousal:.2f}
*(0: ì°¨ë¶„í•¨ â†” 1: í¥ë¶„ë¨)*

**ğŸ¯ ì‹ ë¢°ë„**: {emotion.confidence:.2f}

**ğŸ’­ ë¶„ì„ ê·¼ê±°**: 
{emotion.reasons}"""
            
            brief_text = f"""**ğŸµ ìŒì•… ë¶„ìœ„ê¸°**: {brief.mood}

**ğŸ¥ BPM**: {brief.bpm}

**ğŸ¼ ì¡°ì„±**: {brief.key}

**â±ï¸ ê¸¸ì´**: {brief.duration_sec}ì´ˆ

**ğŸ¹ ì•…ê¸°**: {', '.join(brief.instruments)}

**ğŸ·ï¸ ìŠ¤íƒ€ì¼ íƒœê·¸**: {', '.join(brief.style_tags)}

**ğŸ“ ìƒì„± í”„ë¡¬í”„íŠ¸**: 
{brief.prompt}"""
            
            # Status message
            if provider_used == "skipped":
                status = "âš ï¸ ìŒì•… ìƒì„±ì´ ê±´ë„ˆë›°ì–´ì¡ŒìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
                audio_file = None
            elif provider_used in ["replicate", "rest"]:
                base_status = f"ğŸµ ìŒì•… ìƒì„± ì™„ë£Œ! ({provider_used} ì‚¬ìš©)"
                if 'status_msg' in locals():
                    status = f"{status_msg} â†’ {base_status}"
                else:
                    status = base_status
                audio_file = audio_path if audio_path and os.path.exists(audio_path) else None
            else:
                status = "âŒ ìŒì•… ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
                audio_file = None
            
            return emotion_text, brief_text, audio_file, status
            
        except Exception as e:
            error_msg = f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            return "ì˜¤ë¥˜ ë°œìƒ", "ì˜¤ë¥˜ ë°œìƒ", None, error_msg