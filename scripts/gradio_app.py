import gradio as gr
import os
import json
from pathlib import Path
import tempfile
import shutil

# Import the core music generation functionality
from music_generator_core import (
    graph, GraphState, EmotionResult, MusicBrief,
    dump, generate_with_replicate_strict,
    analyze_emotion_node, compose_brief_node  # Import new nodes
)

class AppState:
    def __init__(self):
        self.emotion_result = None
        self.music_brief = None
        self.user_story = None
    
    def clear(self):
        self.emotion_result = None
        self.music_brief = None
        self.user_story = None
    
    def has_emotion_analysis(self, current_story):
        return (self.emotion_result is not None and 
                self.user_story == current_story)
    
    def has_music_brief(self, current_story):
        return (self.music_brief is not None and 
                self.user_story == current_story)

# Global app state instance
app_state = AppState()

def create_gradio_interface():
    """Create and configure the Gradio interface"""
    
    def analyze_emotion_only(user_story):
        """
        Only analyze emotion without generating music
        
        Args:
            user_story (str): User's emotional story/text
        
        Returns:
            tuple: (emotion_analysis, status_message)
        """
        try:
            if app_state.user_story != user_story:
                app_state.clear()
                app_state.user_story = user_story
            
            # Prepare the state for emotion analysis only
            state = {
                "user_text": user_story,
                "force_generate": False  # Never generate music
            }
            
            # Run only the emotion analysis node directly
            state = analyze_emotion_node(state)
            
            # Extract emotion result
            emotion = state.get("emotion")
            app_state.emotion_result = emotion
            
            emotion_text = f"""**ğŸ­ ì£¼ìš” ê°ì •**: {emotion.primary}

**ğŸ“Š ê°ì • ê°•ë„ (Valence)**: {emotion.valence:.2f}
*(-1: ë§¤ìš° ë¶€ì •ì  â†” +1: ë§¤ìš° ê¸ì •ì )*

**âš¡ ê°ì„±ë„ (Arousal)**: {emotion.arousal:.2f}
*(0: ì°¨ë¶„í•¨ â†” 1: í¥ë¶„ë¨)*

**ğŸ¯ ì‹ ë¢°ë„**: {emotion.confidence:.2f}

**ğŸ’­ ë¶„ì„ ê·¼ê±°**: 
{emotion.reasons}"""
            
            status = "âœ… ê°ì • ë¶„ì„ ì™„ë£Œ! (í¬ë ˆë”§ ì‚¬ìš© ì•ˆí•¨)"
            
            return emotion_text, "", None, status
            
        except Exception as e:
            error_msg = f"âŒ ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            return "ì˜¤ë¥˜ ë°œìƒ", "", None, error_msg
    
    def generate_music_brief_only(user_story):
        """
        Analyze emotion and generate music brief without actual music generation
        
        Args:
            user_story (str): User's emotional story/text
        
        Returns:
            tuple: (emotion_analysis, music_brief, status_message)
        """
        try:
            if app_state.user_story != user_story:
                app_state.clear()
                app_state.user_story = user_story
            
            # Prepare the state
            state = {
                "user_text": user_story,
                "force_generate": False  # Explicitly prevent music generation
            }
            
            if app_state.has_emotion_analysis(user_story):
                state["emotion"] = app_state.emotion_result
            else:
                state = analyze_emotion_node(state)
                app_state.emotion_result = state.get("emotion")
            
            # Run only the brief composition node  
            state = compose_brief_node(state)
            
            # Extract results without running the full graph
            emotion = state.get("emotion")
            brief = state.get("brief")
            app_state.music_brief = brief
            
            emotion_text = f"""**ğŸ­ ì£¼ìš” ê°ì •**: {emotion.primary}

**ğŸ“Š ê°ì • ê°•ë„ (Valence)**: {emotion.valence:.2f}
*(-1: ë§¤ìš° ë¶€ì •ì  â†” +1: ë§¤ìš° ê¸ì •ì )*

**âš¡ ê°ì„±ë„ (Arousal)**: {emotion.arousal:.2f}
*(0: ì°¨ë¶„í•¨ â†” 1: í¥ë¶„ë¨)*

**ğŸ¯ ì‹ ë¢°ë„**: {emotion.confidence:.2f}

**ğŸ’­ ë¶„ì„ ê·¼ê±°**: 
{emotion.reasons}"""
            
            brief_text = f"""**ğŸµ ìŒì•… ë¶„ìœ„ê¸°**: {brief.mood}

**ğŸ¥ BPM**: {brief.bpm}

**ğŸ¼ ì¡°ì„±**: {brief.key}

**â±ï¸ ê¸¸ì´**: {brief.duration_sec}ì´ˆ

**ğŸ¹ ì•…ê¸°**: {', '.join(brief.instruments)}

**ğŸ·ï¸ ìŠ¤íƒ€ì¼ íƒœê·¸**: {', '.join(brief.style_tags)}

**ğŸ“ ìƒì„± í”„ë¡¬í”„íŠ¸**: 
{brief.prompt}"""
            
            status = "âœ… ê°ì • ë¶„ì„ ë° ìŒì•… ë¸Œë¦¬í”„ ìƒì„± ì™„ë£Œ! (í¬ë ˆë”§ ì‚¬ìš© ì•ˆí•¨)"
            
            return emotion_text, brief_text, None, status
            
        except Exception as e:
            error_msg = f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            return "ì˜¤ë¥˜ ë°œìƒ", "ì˜¤ë¥˜ ë°œìƒ", None, error_msg
    
    def generate_full_music(user_story):
        """
        Full pipeline: analyze emotion, generate brief, and create actual music
        Uses cached results if available for the same story
        
        Args:
            user_story (str): User's emotional story/text
        
        Returns:
            tuple: (emotion_analysis, music_brief, audio_file, status_message)
        """
        try:
            if app_state.user_story != user_story:
                app_state.clear()
                app_state.user_story = user_story
            
            # Prepare the state
            state = {
                "user_text": user_story,
                "force_generate": True  # Force music generation
            }
            
            if app_state.has_emotion_analysis(user_story):
                state["emotion"] = app_state.emotion_result
                status_msg = "ğŸ“‹ ì´ì „ ê°ì • ë¶„ì„ ê²°ê³¼ ì¬ì‚¬ìš©"
            
            if app_state.has_music_brief(user_story):
                state["brief"] = app_state.music_brief
                status_msg = "ğŸ“‹ ì´ì „ ë¶„ì„ ê²°ê³¼ ì¬ì‚¬ìš©í•˜ì—¬ ìŒì•… ìƒì„±"
            
            # Run the workflow (will skip already completed steps)
            final_state = graph.invoke(state)
            
            # Extract results
            emotion = final_state.get("emotion")
            brief = final_state.get("brief")
            audio_path = final_state.get("audio_path")
            provider_used = final_state.get("provider_used", "skipped")
            
            emotion_text = f"""**ğŸ­ ì£¼ìš” ê°ì •**: {emotion.primary}

**ğŸ“Š ê°ì • ê°•ë„ (Valence)**: {emotion.valence:.2f}
*(-1: ë§¤ìš° ë¶€ì •ì  â†” +1: ë§¤ìš° ê¸ì •ì )*

**âš¡ ê°ì„±ë„ (Arousal)**: {emotion.arousal:.2f}
*(0: ì°¨ë¶„í•¨ â†” 1: í¥ë¶„ë¨)*

**ğŸ¯ ì‹ ë¢°ë„**: {emotion.confidence:.2f}

**ğŸ’­ ë¶„ì„ ê·¼ê±°**: 
{emotion.reasons}"""
            
            brief_text = f"""**ğŸµ ìŒì•… ë¶„ìœ„ê¸°**: {brief.mood}

**ğŸ¥ BPM**: {brief.bpm}

**ğŸ¼ ì¡°ì„±**: {brief.key}

**â±ï¸ ê¸¸ì´**: {brief.duration_sec}ì´ˆ

**ğŸ¹ ì•…ê¸°**: {', '.join(brief.instruments)}

**ğŸ·ï¸ ìŠ¤íƒ€ì¼ íƒœê·¸**: {', '.join(brief.style_tags)}

**ğŸ“ ìƒì„± í”„ë¡¬í”„íŠ¸**: 
{brief.prompt}"""
            
            # Status message
            if provider_used == "skipped":
                status = "âš ï¸ ìŒì•… ìƒì„±ì´ ê±´ë„ˆë›°ì–´ì¡ŒìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
                audio_file = None
            elif provider_used in ["replicate", "rest"]:
                base_status = f"ğŸµ ìŒì•… ìƒì„± ì™„ë£Œ! ({provider_used} ì‚¬ìš©)"
                if 'status_msg' in locals():
                    status = f"{status_msg} â†’ {base_status}"
                else:
                    status = base_status
                audio_file = audio_path if audio_path and os.path.exists(audio_path) else None
            else:
                status = "âŒ ìŒì•… ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
                audio_file = None
            
            return emotion_text, brief_text, audio_file, status
            
        except Exception as e:
            error_msg = f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            return "ì˜¤ë¥˜ ë°œìƒ", "ì˜¤ë¥˜ ë°œìƒ", None, error_msg
    
    def check_environment():
        """Check if required environment variables are set"""
        openai_ok = bool(os.getenv("OPENAI_API_KEY"))
        replicate_ok = bool(os.getenv("REPLICATE_API_TOKEN"))
        use_replicate = os.getenv("USE_REPLICATE", "0") == "1"
        
        status = f"""**âš™ï¸ í™˜ê²½ ì„¤ì • ìƒíƒœ**:

**OpenAI API**: {'âœ… ì„¤ì •ë¨' if openai_ok else 'âŒ ë¯¸ì„¤ì •'}

**Replicate API**: {'âœ… ì„¤ì •ë¨' if replicate_ok else 'âŒ ë¯¸ì„¤ì •'}

**USE_REPLICATE**: {'âœ… í™œì„±í™”ë¨' if use_replicate else 'âš ï¸ ë¹„í™œì„±í™”ë¨ (0ìœ¼ë¡œ ì„¤ì •)'}

{'âœ… ëª¨ë“  ì„¤ì •ì´ ì™„ë£Œë˜ì–´ ìŒì•… ìƒì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!' if (openai_ok and replicate_ok and use_replicate) else 'âš ï¸ ì‹¤ì œ ìŒì•… ìƒì„±ì„ ìœ„í•´ì„œëŠ” ëª¨ë“  API í‚¤ê°€ í•„ìš”í•˜ê³  USE_REPLICATE=1ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.'}"""
        
        return status
    
    def translate_prompt_to_korean(english_prompt):
        """
        Translate English music generation prompt to Korean
        This is a simple translation helper for better understanding
        """
        pass
    
    # Create the Gradio interface
    with gr.Blocks(
        title="ì¹˜ë£Œìš© ìŒì•… ìƒì„± AI",
        theme=gr.themes.Soft(),
        css="""
        .main-container { max-width: 1200px; margin: 0 auto; }
        .story-input { min-height: 150px; }
        .result-box { border: 1px solid #e0e0e0; border-radius: 8px; padding: 15px; margin: 10px 0; }
        .step-button { margin: 5px; }
        """
    ) as demo:
        
        gr.Markdown("""
        # ğŸµ ê°œì¸ ê°ì • ìŠ¤í† ë¦¬ ê¸°ë°˜ ì¹˜ë£Œìš© ìŒì•… ìƒì„± AI
        
        **ë‹¹ì‹ ì˜ ì´ì•¼ê¸°ì™€ ê°ì •ì„ ë¶„ì„í•˜ì—¬ ë§ì¶¤í˜• ì¹˜ë£Œ ìŒì•…ì„ ìƒì„±í•©ë‹ˆë‹¤**
        
        ì´ AIëŠ” ì˜ˆìˆ ì¹˜ë£Œ ë° ì‹¬ë¦¬ì•ˆì • ì§€ì›ì„ ëª©ì ìœ¼ë¡œ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. 
        ë‹¹ì‹ ì˜ ê°ì • ìƒíƒœë¥¼ ë¶„ì„í•˜ê³ , ê·¸ì— ë§ëŠ” ì¹˜ë£Œì  ìŒì•…ì„ ìƒì„±í•©ë‹ˆë‹¤.
        """)
        
        with gr.Row():
            with gr.Column(scale=2):
                # Input section
                gr.Markdown("## ğŸ“ ë‹¹ì‹ ì˜ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”")
                
                story_input = gr.Textbox(
                    label="ê°ì •ì´ë‚˜ ìƒí™©ì„ ììœ ë¡­ê²Œ ì¨ì£¼ì„¸ìš”",
                    placeholder="ì˜ˆ: ì˜¤ëŠ˜ í•˜ë£¨ ì¢…ì¼ ë§ˆìŒì´ ë¬´ê±°ì› ë‹¤. ì¼ì •ì„ ì •ë¦¬í•˜ë‹¤ê°€ í˜ì´ì§€ë¥¼ ë„˜ê¸°ëŠ” ì†ì´ ìì£¼ ë©ˆì·„ë‹¤. ì‹œê°„ì´ íë¥´ëŠ” ê²Œ ì˜ ëŠê»´ì§€ì§€ ì•Šì•˜ë‹¤...",
                    lines=6,
                    elem_classes=["story-input"]
                )
                
                gr.Markdown("## ğŸ¯ ì›í•˜ëŠ” ì‘ì—…ì„ ì„ íƒí•˜ì„¸ìš”")
                
                with gr.Row():
                    emotion_only_btn = gr.Button(
                        "ğŸ” ê°ì • ë¶„ì„ë§Œ", 
                        variant="secondary", 
                        scale=1,
                        elem_classes=["step-button"]
                    )
                    brief_only_btn = gr.Button(
                        "ğŸ“‹ ê°ì •ë¶„ì„ + ìŒì•…ì„¤ê³„", 
                        variant="primary", 
                        scale=1,
                        elem_classes=["step-button"]
                    )
                    full_generate_btn = gr.Button(
                        "ğŸµ ì „ì²´ ìƒì„± (í¬ë ˆë”§ ì‚¬ìš©)", 
                        variant="primary", 
                        scale=1,
                        elem_classes=["step-button"]
                    )
                
                gr.Markdown("""
                **ğŸ’¡ ì‚¬ìš©ë²•**:
                - **ğŸ” ê°ì • ë¶„ì„ë§Œ**: ë¬´ë£Œë¡œ ê°ì • ìƒíƒœë§Œ ë¶„ì„
                - **ğŸ“‹ ê°ì •ë¶„ì„ + ìŒì•…ì„¤ê³„**: ê°ì • ë¶„ì„ + ìŒì•… ë¸Œë¦¬í”„ ìƒì„± (ë¬´ë£Œ)
                - **ğŸµ ì „ì²´ ìƒì„±**: ì‹¤ì œ ìŒì•… íŒŒì¼ê¹Œì§€ ìƒì„± (Replicate í¬ë ˆë”§ ì‚¬ìš©)
                """)
            
            with gr.Column(scale=1):
                # Environment check
                gr.Markdown("## âš™ï¸ ì‹œìŠ¤í…œ ìƒíƒœ")
                env_status = gr.Markdown(check_environment())
                refresh_btn = gr.Button("ğŸ”„ ìƒíƒœ ìƒˆë¡œê³ ì¹¨", size="sm")
        
        # Results section
        gr.Markdown("## ğŸ“Š ë¶„ì„ ê²°ê³¼")
        
        with gr.Row():
            with gr.Column():
                emotion_output = gr.Markdown(
                    label="ê°ì • ë¶„ì„ ê²°ê³¼",
                    elem_classes=["result-box"]
                )
            
            with gr.Column():
                brief_output = gr.Markdown(
                    label="ìŒì•… ë¸Œë¦¬í”„",
                    elem_classes=["result-box"]
                )
        
        # Audio output and download
        gr.Markdown("## ğŸµ ìƒì„±ëœ ìŒì•…")
        audio_output = gr.Audio(
            label="ì¹˜ë£Œìš© ìŒì•…",
            type="filepath",
            interactive=False
        )
        
        status_output = gr.Markdown("")
        
        emotion_only_btn.click(
            fn=analyze_emotion_only,
            inputs=[story_input],
            outputs=[emotion_output, brief_output, audio_output, status_output]
        )
        
        brief_only_btn.click(
            fn=generate_music_brief_only,
            inputs=[story_input],
            outputs=[emotion_output, brief_output, audio_output, status_output]
        )
        
        full_generate_btn.click(
            fn=generate_full_music,
            inputs=[story_input],
            outputs=[emotion_output, brief_output, audio_output, status_output]
        )
        
        refresh_btn.click(
            fn=check_environment,
            outputs=[env_status]
        )
        
        # Footer
        gr.Markdown("""
        ---
        **ê°œë°œ ì •ë³´**: ì´ AIëŠ” ê°œì¸ì˜ ê°ì •ê³¼ ìŠ¤í† ë¦¬ë¥¼ ë‹´ì€ í¼ìŠ¤ë„ ë®¤ì§ ìƒì„±ì„ í†µí•´ ì˜ˆìˆ ì¹˜ë£Œ ë° ì‹¬ë¦¬ì•ˆì •ì„ ì§€ì›í•©ë‹ˆë‹¤.
        
        **ì£¼ì˜ì‚¬í•­**: 
        - ì´ ë„êµ¬ëŠ” ì „ë¬¸ì ì¸ ì‹¬ë¦¬ì¹˜ë£Œë¥¼ ëŒ€ì²´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
        - ì‹¬ê°í•œ ì •ì‹ ê±´ê°• ë¬¸ì œê°€ ìˆë‹¤ë©´ ì „ë¬¸ê°€ì˜ ë„ì›€ì„ ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤
        - ìƒì„±ëœ ìŒì•…ì€ ê°œì¸ì  ìš©ë„ë¡œë§Œ ì‚¬ìš©í•´ì£¼ì„¸ìš”
        """)
    
    return demo

if __name__ == "__main__":
    # Create and launch the interface
    demo = create_gradio_interface()
    
    # Launch with sharing enabled for easy access
    demo.launch(
        server_name="0.0.0.0",  # Allow external access
        server_port=7860,       # Default Gradio port
        share=True,             # Create public link
        debug=True              # Enable debug mode
    )
